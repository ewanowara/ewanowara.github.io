<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ewa Nowara</title>
  
  <meta name="author" content="Ewa Nowara">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="data/CAM.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ewa Nowara</name>
              <p style="text-align:center">
                Postdoctoral Research Fellow 
              </p>
              <p style="text-align:center"> 
                <a href="https://www.jhu.edu/life/campuses/homewood/">Johns Hopkins University </a> 
              </p>

              <p style="text-align:center">
                <a href="mailto:enowara1@jhu.edu">Email</a> &nbsp/&nbsp
                <a href="data/EwaNowara_resume_online.pdf">CV</a> &nbsp/&nbsp
                <a href="data/EwaNowara-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Am9NsWMAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ewa-nowara-2167458b/">LinkedIn</a>
              </p>

              </p>
                I am a Postdoctoral Research Fellow at Johns Hopkins University working with Prof. <a href="https://engineering.jhu.edu/ece/faculty/rama-chellappa/">Rama Chellappa</a> on geo-localizing natural images. I'm interested in computer vision, machine learning and computational imaging. 
              </p>
              </p>  
                I received my Ph.D. from Rice University in 2021 where I was fortunate to work with Prof. <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a> in the <a href="https://computationalimaging.rice.edu/">Computational Imaging Group</a>. My Ph.D. research focused on deep learning and computational imaging for robust unconstrained camera-based vital signs monitoring, known as imaging photoplethysmography. 
              </p> 

            </td>
            <td style="padding:0.5%;width:30%;max-width:30%">
              <img style="width:70%;max-width:70%" alt="profile photo" src="data/EwaNowara2.jpg">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flare_image'>
                  <img src='data/Benefit_of_Distraction.jpg' width="160"></div>
                <img src='data/Benefit_of_Distraction.jpg' width="160">
              </div>
              
              </div>
             
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.07770">
              <papertitle>The Benefit of Distraction: Denoising Remote Vitals Measurements using Inverse Attention</papertitle></a>
              <br>
              <br>
              </a>
              <br>
              <strong>Ewa M. Nowara</strong>,
              <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
              <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
              
              <br>
              <em>ICCV</em>, 2021 
              <br>
              <a href="https://arxiv.org/abs/2010.07770">arXiv</a>
              /
      
              <a href="https://www.dropbox.com/s/dbr4l4uzz7ayxjn/video_Benefit_of_distraction.mp4?dl=0">video</a>
              
              <p></p>
              <p>We exploit the idea that statistics of corruptions may be shared between the video regions that contain the signal of interest and those that do not. We use the inverse of an attention mask to generate a corruption estimate that is then used to denoise temporal observations.</p>
            </td>
        </tbody>
      
        
        <tr onmouseout="nerfbake_stop1()" onmouseover="nerfbake_start1()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='flare_image'>
                <img src='data/Aug2.jpg' width="160"></div>
              <img src='data/Aug1.jpg' width="160">
            </div>
              
            <script type="text/javascript">
              function nerfbake_start1() {
                document.getElementById('nerfbake_image').style.opacity = "1";
              }

              function nerfbake_stop1() {
                document.getElementById('nerfbake_image').style.opacity = "0";
              }
              nerfbake_stop1()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Nowara_Combining_Magnification_and_Measurement_for_Non-Contact_Cardiac_Monitoring_CVPRW_2021_paper.html">
              <papertitle>Combining Magnification and Measurement for Non-Contact Cardiac Monitoring</papertitle></a>
            <br>
            <strong>Ewa M. Nowara</strong>,
            <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
            <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
            
            <br>
            <em>CVPR Workshops</em>, 2021 
            <br>
            
            <p></p>
            <p> We improve the generalizability of deep learning models for non-contact cardiac monitoring by augmenting the training set videos with ``magnified'' videos. These data augmentations are specifically geared towards revealing useful features for recovering the physiological signals.</p>
          </td>
        </tr> 


        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='data/avatars.jpg' width="160">
            <script type="text/javascript">
              function nerfbake_start() {
                document.getElementById('nerfbake_image').style.opacity = "1";
              }

              function nerfbake_stop() {
                document.getElementById('nerfbake_image').style.opacity = "0";
              }
              nerfbake_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445719">
            <papertitle>“Warm Bodies”: A Post-Processing Technique for Animating Dynamic Blood Flow on Photos and Avatars</papertitle></a>
            </a>
            <br>
            <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
            <strong>Ewa M. Nowara</strong>
            <br>
            <em>CHI</em>, 2021 
            <br>
            <a href="https://arxiv.org/pdf/2103.07987.pdf">arXiv</a>
            /  
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445719">video</a>
            
            <p></p>
            <p>We animate blood flow patterns to augment the appearance of synthetic avatars and photo-realistic faces based on a data-driven physiological model.</p>
          </td>
      </tbody>

      <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one"><img src='data/compression.jpg' width="160">
            <div class="two" id='nerfbake_image'>
          </div>
          <script type="text/javascript">
            function nerfbake_start() {
              document.getElementById('nerfbake_image').style.opacity = "1";
            }

            function nerfbake_stop() {
              document.getElementById('nerfbake_image').style.opacity = "0";
            }
            nerfbake_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.osapublishing.org/boe/fulltext.cfm?uri=boe-12-1-494&id=444959">
          <papertitle>Systematic Analysis of Video-Based Pulse Measurement from Compressed Videos</papertitle></a>
          </a>
          <br>
          <strong>Ewa M. Nowara</strong>,
          <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
          <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
          
          <br>
          <em>Biomedical Optics Express</em>, 2021 
          <br>
          
          <a href="https://www.dropbox.com/s/nbniq5jc41ge1tu/Nowara_Supplementary_Video_Compression.mp4?dl=0">video</a>
          
          <p></p>
          <p>We show that deep learning models can learn how noise at different video compression levels affects the physiological signals and are able to reliably recover vital signs from highly compressed videos, even in presence of large motion.</p>
        </td>
    </tbody>

    <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nerfbake_image'><img src='data/driving.jpg' width="160">
        </div>
        <script type="text/javascript">
          function nerfbake_start() {
            document.getElementById('nerfbake_image').style.opacity = "1";
          }

          function nerfbake_stop() {
            document.getElementById('nerfbake_image').style.opacity = "0";
          }
          nerfbake_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9275394">
        <papertitle>Near-Infrared Imaging Photoplethysmography During Driving</papertitle></a>
        </a>
        <br>
        <strong>Ewa M. Nowara</strong>,
        <a href="https://www.merl.com/people/tmarks">Tim K. Marks</a>,
        <a href="https://www.merl.com/people/mansour">Hassan Mansour</a>,
       
        <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
        
        <br>
        <em>Trans. on Intelligent Transportation Systems</em>, 2020 
        <br>
        
        <a href="https://www.dropbox.com/s/4rv9xm2u6li71h9/Video_SupplementaryMaterials.mp4?dl=0">video</a>
        
        <p></p>
        <p>We demonstrate that we can reduce most outside light variations using narrow-band near-infrared (NIR) video recordings and obtain reliable heart rate estimates. We present a novel optimization algorithm, which we call AutoSparsePPG, that leverages the quasi-periodicity of physiological signals and achieves better performance than the state-of-the-art methods.</p>
      </td>
  </tbody>

          
        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='nerfbake_image'><img src='data/skin_tone.jpg' width="160">
            </div>
            <script type="text/javascript">
              function nerfbake_start() {
                document.getElementById('nerfbake_image').style.opacity = "1";
              }

              function nerfbake_stop() {
                document.getElementById('nerfbake_image').style.opacity = "0";
              }
              nerfbake_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w19/Nowara_A_Meta-Analysis_of_the_Impact_of_Skin_Tone_and_Gender_CVPRW_2020_paper.html">
            <papertitle>A Meta-Analysis of the Impact of Skin Tone and Gender on Non-Contact Photoplethysmography Measurements</papertitle></a>
            </a>
            <br>
            <strong>Ewa M. Nowara</strong>,
            <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
            <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
            
            <br>
            <em>CVPR Workshop</em>, 2020
            <br>
            <a href="https://www.dropbox.com/s/h4ee51nudxgcq7b/6-oral.mp4?dl=0">video</a>
            
            <p></p>
            <p> We evaluate how much gender and skin tone affect vital signs estimation from video. We find that the performance drops significantly on videos of people with very dark skin tones, especially for machine learning algorithms. </p>
          </td>
      </tbody>

      <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='nerfbake_image'><img src='data/3DPPG.jpg' width="160">
          </div>
          <script type="text/javascript">
            function nerfbake_start() {
              document.getElementById('nerfbake_image').style.opacity = "1";
            }

            function nerfbake_stop() {
              document.getElementById('nerfbake_image').style.opacity = "0";
            }
            nerfbake_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176065">
          <papertitle>PPG3D: Does 3D head tracking improve camera-based PPG estimation?</papertitle></a>
          </a>
          <br>
          <a href="https://www.researchgate.net/scientific-contributions/Genki-Nagamatsu-2159873682">Genki Nagamatsu</a>,
          <strong>Ewa M. Nowara</strong>,
          <a href="https://amruta.blogs.rice.edu/">Amruta Pai</a>,
          <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
          <a href="https://scholar.google.co.jp/citations?user=OkKk5rMAAAAJ&hl=ja">Hiroshi Kawasaki</a>
          
          <br>
          <em>EMBC</em>, 2020 
          <br>
          <p></p>
          <p>We use 3D face tracking to estimate the position of facial landmarks with pixel-level accuracy to improve motion robustness of camera-based vital sign estimation.</p>
        </td>
    </tbody>

    <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
      <td style="padding:20px;width:25%;vertical-align:top">
        <div class="one">
          <div class="two" id='nerfbake_image'><img src='data/compr.jpg' width="160">
        </div>
        <script type="text/javascript">
          function nerfbake_start() {
            document.getElementById('nerfbake_image').style.opacity = "1";
          }

          function nerfbake_stop() {
            document.getElementById('nerfbake_image').style.opacity = "0";
          }
          nerfbake_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top">
        <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVPM/Nowara_Combating_the_Impact_of_Video_Compression_on_Non-Contact_Vital_Sign_ICCVW_2019_paper.pdf">
        <papertitle>Combating the Impact of Video Compression on Non-Contact Vital Sign Measurement Using Supervised Learning</papertitle></a>
        </a>
        <br>
        <strong>Ewa M. Nowara</strong>,
        <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>
        
        <br>
        <em>ICCV</em>, 2019 
        <br>
                
        <p></p>
        <p>We demonstrate that very small intensity variations in the skin related to physiological signals can be recovered even from very compressed videos with supervised deep learning.</p>
      </td>
  </tbody>

  <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='nerfbake_image'><img src='data/SparsePPG.jpg' width="160">
      </div>
      <script type="text/javascript">
        function nerfbake_start() {
          document.getElementById('nerfbake_image').style.opacity = "1";
        }

        function nerfbake_stop() {
          document.getElementById('nerfbake_image').style.opacity = "0";
        }
        nerfbake_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w27/Nowara_SparsePPG_Towards_Driver_CVPR_2018_paper.pdf">
      <papertitle>SparsePPG: Towards Driver Monitoring Using Camera-Based Vital Signs Estimation in Near-Infrared</papertitle></a>
      </a>
      <br>
      <strong>Ewa M. Nowara</strong>,
      <a href="https://www.merl.com/people/tmarks">Tim K. Marks</a>,
      <a href="https://www.merl.com/people/mansour">Hassan Mansour</a>,
      <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
      
      <br>
      <em>CVPR Workshops</em>, 2018 
      <br>
      
      <p></p>
      <p>We demonstrate the feasibility of using narrow-bandwidth near-infrared (NIR) active illumination at 940 nm for camera-based vital signs measurements. We develop a novel signal tracking and denoising algorithm (SparsePPG) based on Robust Principal Components Analysis and sparse frequency spectrum estimation. </p>
    </td>
</tbody>

    <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
      <td style="padding:20px;width:25%;vertical-align:top">
        <div class="one">
          <div class="two" id='nerfbake_image'><img src='data/PPGSecure.jpg' width="160">
        </div>
        <script type="text/javascript">
          function nerfbake_start() {
            document.getElementById('nerfbake_image').style.opacity = "1";
          }

          function nerfbake_stop() {
            document.getElementById('nerfbake_image').style.opacity = "0";
          }
          nerfbake_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top">
        <a href="https://ieeexplore.ieee.org/document/7961723">
        <papertitle>PPGsecure: Biometric Presentation Attack Detection Using Photoplethysmograms</papertitle></a>
        </a>
        <br>
        <strong>Ewa M. Nowara</strong>,
        <a href="https://ashu.rice.edu/">Ashutosh Sabharwal</a>,
        <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>
        
        <br>
        <em>Face and Gesture</em>, 2017 
        <br>
        
        <p>We developed a machine learning system to prevent face spoofing attacks by detecting and analyzing the heartbeat signal from the face videos.</p>
      </td>
  </tbody>
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Patents</heading>
          <p>
            T Marks, H Mansour, <strong>E Nowara</strong>, Y Nakamura, A Veeraraghavan
            <a href="https://patentimages.storage.googleapis.com/68/74/59/c9afaa8c42923f/US20190350471A1.pdf">
            <papertitle>System and method for remote measurements of vital signs</papertitle></a>
            US Patent App. 16/167,668 2019
          <p>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Dissertation</heading>
        </td>
        </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="nerfbake_stop1()" onmouseover="nerfbake_start1()">
        <td style="padding:20px;width:25%;vertical-align:top">
        <div class="one">
        <div class="two" id='flare_image'>
        <img src='data/Rice_logo.jpg' width="80"></div>
        <img src='data/Rice_logo.jpg' width="80">
        </div>
        <script type="text/javascript">
        function nerfbake_start1() {
        document.getElementById('nerfbake_image').style.opacity = "1";
        }
        function nerfbake_stop1() {
        document.getElementById('nerfbake_image').style.opacity = "0";
        }
        nerfbake_stop1()
        </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
        <a href="https://scholarship.rice.edu/handle/1911/110424">
        <papertitle>Towards Robust Imaging Photoplethysmography in Unconstrained Settings</papertitle> </a>
        </a>
        <br>
        <strong>Ewa M. Nowara</strong>
        <br>
        <em>Electrical and Computer Engineering, Rice University</em>, April 2021 
        <br>
        
        </td>
        </tr> 
        </table>
          

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Awards and Honors</heading>

          <ul>
            <li>Invited attendee, Microsoft Research AI Breakthroughs (2020)</li>
            <li> Best graduate poster and demo award at ECE Corporate Affiliates Day at Rice for “SparsePPG: Towards Driver Monitoring Using Camera-Based Vital Signs Estimation in Near-Infrared.” (2019)</li>
            <li>The Ken Kennedy Institute for Information Technology 2017/18 Schlumberger Graduate Fellowship  (2017-18)</li>
            <li>Selected attendee, Doctoral Consortium at Automatic Face and Gesture Recognition (2017)</li>
            <li>Selected attendee, CRA-W (Computing Research Association) Grad Cohort (2016)</li>
            <li>Texas Instruments Fellowship (2015)</li>
            <li>Presidential Award (given to top 14 graduating seniors) (2015)</li>
            <li>Best undergraduate talk award in Computational Chemistry at GCURS (Gulf Coast Undergraduate Regional Symposium) at Rice University (2015) [poster].</li>
            
            <li>Research Featured in St. Mary’s University Publication <a href="https://issuu.com/stmarysu/docs/gold_blue_winter2012_issuu_1212">‘Gold and Blue’ Magazine</a>— ‘Polish Student’s Research Looks for Clues to Parkinson’s Disease’—Author: Chris Jarvis.  (2012, pages 10-11)</li>
          </ul>

        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-right:auto;"><tbody>

      Website credits to <a href="https://jonbarron.info/">Jon Barron</a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-right:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
