<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ewa Nowara</title>
  
  <meta name="author" content="Ewa Nowara">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ewa Nowara</name>
              </p>
                I am a Postdoctoral Research Fellow at Joohns Hopkins University where I work with <a href=" ">Prof. Rama Chellappa</a>, on computer vision and deep learning. I am currently working on geo-localizing natural images. 
              </p>
              </p>  
                I received my Ph.D. from  <a href=" ">Rice University</a> in 2021 where I worked in the Computational Imaging Group with Prof. Ashok Veeraraghavan. Druing my Ph.D. I built systems for robust camera-based vital signs monitoring for real-life applications. 
              </p> 
             
              <p style="text-align:center">
                <a href="mailto:enowara1@jhu.edu">Email</a> &nbsp/&nbsp
                <a href="data/EwaNowara_resume_online.pdf">CV</a> &nbsp/&nbsp
                <a href="data/EwaNowara-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Am9NsWMAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ewa-nowara-2167458b/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/ewanowara/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data/EwaNowara2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="data/EwaNowara2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><img src='data/IMAGE.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href=""></a>
              <papertitle>Title</papertitle>
              </a>
              <br>
              <strong>Ewa M. Nowara</strong>,
              <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
              <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
              
              <br>
              <em>Venue</em>, Year 
              <br>
              <a href="">arXiv</a>
              /
              <a href=
              >bibtex</a>
              /  
              <a href="">video</a>
              /
              <p></p>
              <p>Description.</p>
            </td>
        </tbody>



        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='nerfbake_image'><img src='data/IMAGE.jpg' width="160">
            </div>
            <script type="text/javascript">
              function nerfbake_start() {
                document.getElementById('nerfbake_image').style.opacity = "1";
              }

              function nerfbake_stop() {
                document.getElementById('nerfbake_image').style.opacity = "0";
              }
              nerfbake_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href=""></a>
            <papertitle>Combining Magnification and Measurement for Non-Contact Cardiac Monitoring</papertitle>
            </a>
            <br>
            <strong>Ewa M. Nowara</strong>,
            <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
            <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
            
            <br>
            <em>CVPR Workshops</em>, 2021 
            <br>
            
            <a href="">bibtex</a>
            /  
            <a href="">video</a>
            /
            <p></p>
            <p> In this paper, we show that the generalizability of imaging photoplethysmography models can be improved by augmenting the training set with ``magnified'' videos. These augmentations are specifically geared towards revealing useful features for recovering the photoplethysmogram.</p>
          </td>
      </tbody>


        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='nerfbake_image'><img src='data/IMAGE.jpg' width="160">
            </div>
            <script type="text/javascript">
              function nerfbake_start() {
                document.getElementById('nerfbake_image').style.opacity = "1";
              }

              function nerfbake_stop() {
                document.getElementById('nerfbake_image').style.opacity = "0";
              }
              nerfbake_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445719"></a>
            <papertitle>“Warm Bodies”: A Post-Processing Technique for Animating Dynamic Blood Flow on Photos and Avatars</papertitle>
            </a>
            <br>
            <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
            <strong>Ewa M. Nowara</strong>
            <br>
            <em>CHI</em>, 2021 
            <br>
            <a href="https://arxiv.org/pdf/2103.07987.pdf">arXiv</a>
            /
            <a href=
            >bibtex</a>
            /  
            <a href="https://dl.acm.org/doi/10.1145/3411764.3445719">video</a>
            /
            <p></p>
            <p>We propose a method for animating blood flow patterns, based on a data-driven physiological model that can be used to directly augment the appearance of synthetic avatars and photo-realistic faces.</p>
          </td>
      </tbody>

      <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='nerfbake_image'><img src='data/compression.jpg' width="160">
          </div>
          <script type="text/javascript">
            function nerfbake_start() {
              document.getElementById('nerfbake_image').style.opacity = "1";
            }

            function nerfbake_stop() {
              document.getElementById('nerfbake_image').style.opacity = "0";
            }
            nerfbake_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.osapublishing.org/boe/fulltext.cfm?uri=boe-12-1-494&id=444959"></a>
          <papertitle>Systematic analysis of video-based pulse measurement from compressed videos</papertitle>
          </a>
          <br>
          <strong>Ewa M. Nowara</strong>,
          <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
          <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
          
          <br>
          <em>Biomedical Optics Express</em>, 2021 
          <br>
          
          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:iYKadJSzHbQJ:scholar.google.com/&output=citation&scisdr=CgXjt_1IEP7GkTJO2_M:AAGBfm0AAAAAYLFIw_PI--dsOqx2Nk7re0oBldESAts7&scisig=AAGBfm0AAAAAYLFIw1nfGaj40QgEO39hC1ye5ONrTtBC&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
          /  
          <a href="https://www.dropbox.com/s/nbniq5jc41ge1tu/Nowara_Supplementary_Video_Compression.mp4?dl=0">video</a>
          /
          <p></p>
          <p>We show that deep learning models can learn how noise at different video compression levels affects the iPPG signals and are able to reliably recover vital signs from highly compressed videos, even in presence of large motion.</p>
        </td>
    </tbody>

    <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nerfbake_image'><img src='data/driving.jpg' width="160">
        </div>
        <script type="text/javascript">
          function nerfbake_start() {
            document.getElementById('nerfbake_image').style.opacity = "1";
          }

          function nerfbake_stop() {
            document.getElementById('nerfbake_image').style.opacity = "0";
          }
          nerfbake_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9275394"></a>
        <papertitle>Near-Infrared Imaging Photoplethysmography During Driving</papertitle>
        </a>
        <br>
        <strong>Ewa M. Nowara</strong>,
        <a href="https://www.merl.com/people/tmarks">Tim K. Marks</a>,
        <a href="https://www.merl.com/people/mansour">Hassan Mansour</a>,
       
        <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
        
        <br>
        <em>Trans. on Intelligent Transportation Systems</em>, 2020 
        <br>
        <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:b2ZTs2Cz1CQJ:scholar.google.com/&output=citation&scisdr=CgXjt_1IEP7GkTJPdKw:AAGBfm0AAAAAYLFJbKyuGkV_pVCCWusqt-CCSU9wXFpE&scisig=AAGBfm0AAAAAYLFJbBhbytQmTQEPtKiaK6cO5Ux2MzLf&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
        /  
        <a href="https://www.dropbox.com/s/4rv9xm2u6li71h9/Video_SupplementaryMaterials.mp4?dl=0">video</a>
        /
        <p></p>
        <p>We demonstrate that we can reduce most outside light variations using narrow-band near-infrared (NIR) video recordings and obtain reliable heart rate estimates. We present a novel optimization algorithm, which we call AutoSparsePPG, that leverages the quasi-periodicity of iPPG signals and achieves better performance than the state-of-the-art methods.</p>
      </td>
  </tbody>

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><img src='data/Benefit_of_Distraction.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.07770"></a>
              <papertitle>Benefit of Distraction: Denoising Vitals using Inverse Attention</papertitle>
              </a>
              <br>
              <strong>Ewa M. Nowara</strong>,
              <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
              <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
              
              <br>
              <em>arXiv</em>, 2020 
              <br>
              <a href="https://arxiv.org/abs/2010.07770">arXiv</a>
              /
              <a href=https://scholar.googleusercontent.com/scholar.bib?q=info:WdjOF__pZTQJ:scholar.google.com/&output=citation&scisdr=CgXjt_1IEP7GkTJFdZc:AAGBfm0AAAAAYLFDbZdMIAtcm7ip4xZD9LCxks_Kdxwm&scisig=AAGBfm0AAAAAYLFDbS-dAE5wOeSvzxNumCgwhHdsNv6X&scisf=4&ct=citation&cd=-1&hl=en>bibtex</a>
              /  
              <a href="https://www.dropbox.com/s/dbr4l4uzz7ayxjn/video_Benefit_of_distraction.mp4?dl=0">video</a>
              /
              <p></p>
              <p>We present an approach that exploits the idea that statistics of noise may be shared between the regions that contain the signal of interest and those that do not. Our technique uses the inverse of an attention mask to generate a noise estimate that is then used to denoise temporal observations.</p>
            </td>
        </tbody>
      
        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='nerfbake_image'><img src='data/skin_tone.jpg' width="160">
            </div>
            <script type="text/javascript">
              function nerfbake_start() {
                document.getElementById('nerfbake_image').style.opacity = "1";
              }

              function nerfbake_stop() {
                document.getElementById('nerfbake_image').style.opacity = "0";
              }
              nerfbake_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w19/Nowara_A_Meta-Analysis_of_the_Impact_of_Skin_Tone_and_Gender_CVPRW_2020_paper.html"></a>
            <papertitle>Impact of Skin Type and Gender on Non-contact Photoplethysmography Measurements</papertitle>
            </a>
            <br>
            <strong>Ewa M. Nowara</strong>,
            <a href="https://www.microsoft.com/en-us/research/people/damcduff/">Daniel McDuff</a>,
            <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
            
            <br>
            <em>Workshop</em>, 2020
            <br>
            <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:8m8G5bYMj5UJ:scholar.google.com/&output=citation&scisdr=CgXjt_1IEP7GkTJE_s4:AAGBfm0AAAAAYLFC5s64_JmbDt4WrSgXrGAte8Hn2Pmx&scisig=AAGBfm0AAAAAYLFC5iQXMMQt0eTOoACxyJJsh8CqzQys&scisf=4&ct=citation&cd=-1&hl=enhttps://scholar.googleusercontent.com/scholar.bib?q=info:8m8G5bYMj5UJ:scholar.google.com/&output=citation&scisdr=CgXjt_1IEP7GkTJE_s4:AAGBfm0AAAAAYLFC5s64_JmbDt4WrSgXrGAte8Hn2Pmx&scisig=AAGBfm0AAAAAYLFC5iQXMMQt0eTOoACxyJJsh8CqzQys&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
            /
            <a href="">video</a>
            /
            <p></p>
            <p> We performed a large meta-analysis to evaluate how much gender and skin tone affect vital signs estimation from video for signal-processing-based  and supervised machine learning methods. We find that performance drops significantly on videos of people with very dark skin tones, especially for machine learning algorithms. </p>
          </td>
      </tbody>

      <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='nerfbake_image'><img src='data/3DPPG.jpg' width="160">
          </div>
          <script type="text/javascript">
            function nerfbake_start() {
              document.getElementById('nerfbake_image').style.opacity = "1";
            }

            function nerfbake_stop() {
              document.getElementById('nerfbake_image').style.opacity = "0";
            }
            nerfbake_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176065"></a>
          <papertitle>3D Face Tracking for Motion-Robust Vital Signs</papertitle>
          </a>
          <br>
          <a href="https://www.researchgate.net/scientific-contributions/Genki-Nagamatsu-2159873682">Genki Nagamatsu</a>,
          <strong>Ewa M. Nowara</strong>,
          <a href="https://amruta.blogs.rice.edu/">Amruta Pai</a>,
          <a href="http://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
          <a href="https://scholar.google.co.jp/citations?user=OkKk5rMAAAAJ&hl=ja">Hiroshi Kawasaki</a>
          
          <br>
          <em>EMBC</em>, 2020 
          <br>

          <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Zf73ctWji1gJ:scholar.google.com/&output=citation&scisdr=CgXjt_1IEP7GkTJCVMY:AAGBfm0AAAAAYLFETMbU4MpSEqfQAgGiuAouIVpilS-j&scisig=AAGBfm0AAAAAYLFETMcEl-H2Fr2PZ9Yv7Rmn4G-hkPLI&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
          <p></p>
          <p>We use 3D face tracking to estimate the position of facial landmarks with pixel-level accuracy, even in presence of large head motion.</p>
        </td>
    </tbody>



      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Patents</heading>
          
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Awards and Honors</heading>
          
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      Website credits to <a href="https://jonbarron.info/">Jon Barron</a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
